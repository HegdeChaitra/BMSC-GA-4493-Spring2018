{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Learning in Medicine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## BMSC-GA 4493, BMIN-GA 3007Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lab 7: Word Embedding & RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Goal:\n",
    "- Basics of word embedding and how to use them\n",
    "- Understand the mechanics of RNNs in Pytorch\n",
    "- Train RNN based neural networks on text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When using deep learning methods on NLP tasks, we usually utilize [word embedding](https://en.wikipedia.org/wiki/Word_embedding). To put it briefly, word embedding represent words, or tokens, in a vocabulary as a distributed numerical vector. There are a lot of methods to obtain a word embedding, with some of the most famous being Word2Vec, GloVe, and fastText. It is not difficult to find a general purpose word embedding trained by one of the aforementioned methods on the Internet that's been trained with a massive amount of data. It is usually a good idea to use these pre-trained embedding to save yourself some time and computing resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this lab, we will be using the [GloVe embedding](https://nlp.stanford.edu/projects/glove/) developed by Stanford,  one of the state-of-the-art word embedding. Please download the file ```glove.6B.50d.txt``` from the Resources tab in NYUClasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:07, 54212.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# load embedding\n",
    "emb_dim = 50\n",
    "with open('./glove.6B.50d.txt') as f:\n",
    "    loaded_embeddings = []\n",
    "    words = {}\n",
    "    chars = {}\n",
    "    idx2words = {}\n",
    "    ordered_words = []\n",
    "\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        s = line.split()\n",
    "        loaded_embeddings.append(np.asarray(s[1:]))\n",
    "        \n",
    "        words[s[0]] = len(words)\n",
    "        idx2words[i] = s[0]\n",
    "        ordered_words.append(s[0])\n",
    "        \n",
    "# add unknown to word and char\n",
    "loaded_embeddings.append(np.random.rand(emb_dim))\n",
    "words[\"<UNK>\"] = len(words)\n",
    "\n",
    "# add padding\n",
    "loaded_embeddings.append(np.zeros(emb_dim))\n",
    "words[\"<PAD>\"] = len(words)\n",
    "\n",
    "chars[\"<UNK>\"] = len(chars)\n",
    "chars[\"<PAD>\"] = len(chars)\n",
    "\n",
    "loaded_embeddings = np.array(loaded_embeddings).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we have three variables\n",
    "- ```loaded_embeddings``` of shape [106687, 50] consisting of the actual vectors,\n",
    "- ```words```, a dictionary consisting of each token in the vocabulary and its corresponding row in ```loaded_embeddings```, and\n",
    "- ```idx2words```, a list consisting of all the words in their order in ```loaded_embeddings```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With these, we can use the function below to play around with words to get a sense of how word embedding can be used to represent words. To lookup a word's vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.3074e-01,  4.0117e-01, -4.0785e-01,  1.5444e-01,  4.7782e-01,\n",
       "        2.0754e-01, -2.6951e-01, -3.4023e-01, -1.0879e-01,  1.0563e-01,\n",
       "       -1.0289e-01,  1.0849e-01, -4.9681e-01, -2.5128e-01,  8.4025e-01,\n",
       "        3.8949e-01,  3.2284e-01, -2.2797e-01, -4.4342e-01, -3.1649e-01,\n",
       "       -1.2406e-01, -2.8170e-01,  1.9467e-01,  5.5513e-02,  5.6705e-01,\n",
       "       -1.7419e+00, -9.1145e-01,  2.7036e-01,  4.1927e-01,  2.0279e-02,\n",
       "        4.0405e+00, -2.4943e-01, -2.0416e-01, -6.2762e-01, -5.4783e-02,\n",
       "       -2.6883e-01,  1.8444e-01,  1.8204e-01, -2.3536e-01, -1.6155e-01,\n",
       "       -2.7655e-01,  3.5506e-02, -3.8211e-01, -7.5134e-04, -2.4822e-01,\n",
       "        2.8164e-01,  1.2819e-01,  2.8762e-01,  1.4440e-01,  2.3611e-01])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_embeddings[words['this']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These numbers might not make sense to us, but we can use this in a different way. Please complete the function below, which looks up the most similar words to a given word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def find_nearest(ref_vec, words, embedding, topk=5):\n",
    "    \"\"\"\n",
    "    Finds the top-k most similar words to \"word\" in terms of cosine similarity in the given embedding\n",
    "    :param ref_vec: reference word vector\n",
    "    :param words: dict, word to its index in the embedding\n",
    "    :param embedding: numpy array of shape [V, embedding_dim]\n",
    "    :param topk: number of top candidates to return\n",
    "    :return a list of top-k most similar words\n",
    "    \"\"\"\n",
    "    # TODO: compute cosine similarities\n",
    "    scored_words = None\n",
    "    \n",
    "    # TODO: sort the words by similarity and return the topk\n",
    "    sorted_words = None\n",
    "    \n",
    "    return [(idx2words[w], scored_words[w]) for w in sorted_words[:topk]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hate', 0.9999999999999998),\n",
       " ('hatred', 0.7746837233748827),\n",
       " ('shame', 0.7489536581704521),\n",
       " ('racist', 0.7371559111440316),\n",
       " ('anyone', 0.7364716727627106)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(loaded_embeddings[words['hate']], words, loaded_embeddings, topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', 0.8109660213826736)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(loaded_embeddings[words['worse']] - loaded_embeddings[words['better']] + loaded_embeddings[words['best']],\n",
    "            words, loaded_embeddings, topk=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.8706067438874707)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(loaded_embeddings[words['king']] - loaded_embeddings[words['queen']] + loaded_embeddings[words['woman']],\n",
    "            words, loaded_embeddings, topk=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, let's read in the data. We will be using the [First GOP Debate Twitter Sentiment dataset](https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras/data), which contains Tweets after the first GOP debate and their sentiments (among other stuff). The dataset can be downloaded [here](https://www.kaggle.com/crowdflower/first-gop-debate-twitter-sentiment/downloads/Sentiment.csv/2). Please save it in the same directory as this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold             ...              \\\n",
       "0                     1.0000            NaN             ...               \n",
       "1                     1.0000            NaN             ...               \n",
       "2                     0.6629            NaN             ...               \n",
       "3                     0.7039            NaN             ...               \n",
       "4                     1.0000            NaN             ...               \n",
       "\n",
       "  relevant_yn_gold retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0              NaN             5             NaN                 NaN   \n",
       "1              NaN            26             NaN                 NaN   \n",
       "2              NaN            27             NaN                 NaN   \n",
       "3              NaN           138             NaN                 NaN   \n",
       "4              NaN           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "np.random.seed(1111)\n",
    "\n",
    "df = pd.read_csv('Sentiment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>8493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>3142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>2236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "Negative   8493\n",
       "Neutral    3142\n",
       "Positive   2236"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['sentiment', 'text']]\n",
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For simplicity, we're only going to look at positive and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "0          8493\n",
       "1          2236"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['sentiment'] != 'Neutral']\n",
    "df['sentiment'] = [1 if s == \"Positive\" else 0 for s in df['sentiment']]\n",
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9119 1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timhsu/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.15)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.471433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.528567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "sentiment           \n",
       "0          79.471433\n",
       "1          20.528567"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('sentiment').count().apply(lambda x: 100 * x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.608696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text\n",
       "sentiment           \n",
       "0          77.391304\n",
       "1          22.608696"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.groupby('sentiment').count().apply(lambda x: 100 * x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = train_data['text'], train_data['sentiment']\n",
    "test_X, test_y = test_data['text'], test_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment                                                    0\n",
       "text         RT @ericstonestreet: Trump has Cam hands. #GOP...\n",
       "Name: 12241, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to use the concept of word embedding, we need to build a vocabulary for our model. We will build our vocabulary on the tokens from the training data only. Any words that are not in our vocabulary will be replaced with an ```<UNK>``` token. We will also add a ```<PAD>``` token as padding.\n",
    "\n",
    "For computational purposes, we'll only take words that appeared more than 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2189\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "UNK = \"<UNK>\"\n",
    "PAD = \"<PAD>\"\n",
    "def build_vocab(sentences, min_count=5, max_vocab=None):\n",
    "    \"\"\"\n",
    "    Build vocabulary from sentences (list of strings)\n",
    "    \"\"\"\n",
    "    # keep track of the number of appearance of each word\n",
    "    word_count = Counter()\n",
    "    \n",
    "    for s in sentences:\n",
    "        word_count.update(re.findall(r\"[\\w']+|[.,!?;]\", s.lower()))\n",
    "    \n",
    "    vocabulary = list([w for w in word_count if word_count[w] > min_count]) + [UNK, PAD]\n",
    "    indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    return vocabulary, indices\n",
    "    \n",
    "vocabulary, vocab_indices = build_vocab(train_X)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we'll have to convert each token in the sentences into its index corresponding to our vocabulary so that pytorch can use it. We'll also pad our sentences to a fixed length of 25 tokens so that we can do batch processing. We will do this for all three sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_padded_index_sequences(words, sentences, pad_length=100):\n",
    "    padded_sequences = np.zeros((len(sentences), pad_length))\n",
    "    for i, s in enumerate(sentences):\n",
    "        indices = np.ones(pad_length) * words['<PAD>']\n",
    "        # only take the first 100\n",
    "        token_indices = np.array([words[w] if w in words else words['<UNK>'] for w in re.findall(r\"[\\w']+|[.,!?;]\", s.lower())[:pad_length]])\n",
    "        indices[:len(token_indices)] = token_indices\n",
    "        padded_sequences[i] = indices\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_X = sentences_to_padded_index_sequences(vocab_indices, train_X, 25)\n",
    "test_X = sentences_to_padded_index_sequences(vocab_indices, test_X, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9119, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## For PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, sentences, labels):\n",
    "        self.sentences = sentences.astype(int)\n",
    "        self.labels = np.array(labels).astype(int)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return (torch.LongTensor(self.sentences[key]), self.labels[key])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(TweetDataset(train_X, train_y),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(TweetDataset(test_X, test_y),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a0cc1c9f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test_model(loader, model, limit=None):\n",
    "    \"\"\"\n",
    "    Help function that tests the models's performance on a dataset\n",
    "    :param: loader: data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    truths = []\n",
    "    \n",
    "    for i, (data, labels) in enumerate(loader):\n",
    "        if i and i==limit:\n",
    "            break\n",
    "        outputs = model(Variable(data)).squeeze()\n",
    "        predicted = ((outputs.data > 0.5).long()).view(-1)\n",
    "        predictions += list(predicted.numpy())\n",
    "        truths += list(labels.numpy())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    model.train()\n",
    "    return (100 * correct / total), roc_auc_score(truths, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LOG_INTERVAL = 100\n",
    "\n",
    "def train(num_epoch, model):\n",
    "    for epoch in range(num_epoch):\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "            outputs = model(Variable(data))\n",
    "            model.zero_grad()\n",
    "            loss = loss_function(outputs.squeeze(), Variable(labels.float()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "             # report performance\n",
    "            if (i + 1) % LOG_INTERVAL == 0:\n",
    "                test_acc, test_auc = test_model(test_loader, model)\n",
    "                print('Epoch: [{0}/{1}], Step: [{2}/{3}], Loss: {4}, Validation Acc:{5}, AUC:{6}'.format(\n",
    "                    epoch + 1, EPOCHS, i + 1, len(train_loader), loss.data[0], test_acc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For this lab, we will be exploring two variants of RNN: vanilla (or Elman) RNN and LSTM (Long-short term memory). In the following blocks, please try to define your own model. Some modules in ```torch.nn``` might be really helpful for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, \n",
    "                 vocab_size, embedding_dim, dropout=0.2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # TODO: RNN with dropout, remember to set batch_first to True\n",
    "        self.rnn = None\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self, bsz):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state values\n",
    "        \"\"\"\n",
    "        # TODO: initialize RNN values\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        # TODO: take last hidden state of RNN\n",
    "        \n",
    "        out = F.sigmoid(self.fc(last_hidden))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because the dataset is imbalanced, we will also use AUC as the metric. If everything checks out, you should be able to get about 82% accuracy and an AUC of about 0.6 after 10 epochs of training with the provided parameters with a vanilla RNN. It might be difficult to achieve a better performance than this with a vanilla RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [100/285], Loss: 0.4389716684818268, Validation Acc:77.3913043478261, AUC:0.5\n",
      "Epoch: [1/10], Step: [200/285], Loss: 0.5644798874855042, Validation Acc:77.70186335403727, AUC:0.5107575009260402\n",
      "Epoch: [2/10], Step: [100/285], Loss: 0.7684984803199768, Validation Acc:78.75776397515529, AUC:0.5448049141869367\n",
      "Epoch: [2/10], Step: [200/285], Loss: 0.32810139656066895, Validation Acc:78.01242236024845, AUC:0.5185979750586492\n",
      "Epoch: [3/10], Step: [100/285], Loss: 0.4594899117946625, Validation Acc:78.75776397515529, AUC:0.5360538338066427\n",
      "Epoch: [3/10], Step: [200/285], Loss: 0.429439902305603, Validation Acc:78.94409937888199, AUC:0.5430917397209533\n",
      "Epoch: [4/10], Step: [100/285], Loss: 0.49390771985054016, Validation Acc:79.1304347826087, AUC:0.5540190146931719\n",
      "Epoch: [4/10], Step: [200/285], Loss: 0.4100034236907959, Validation Acc:79.00621118012423, AUC:0.5600228423262131\n",
      "Epoch: [5/10], Step: [100/285], Loss: 0.42685821652412415, Validation Acc:79.25465838509317, AUC:0.5791301395233979\n",
      "Epoch: [5/10], Step: [200/285], Loss: 0.6294975280761719, Validation Acc:79.06832298136646, AUC:0.5497283615261144\n",
      "Epoch: [6/10], Step: [100/285], Loss: 0.37783029675483704, Validation Acc:79.1304347826087, AUC:0.5899956784788246\n",
      "Epoch: [6/10], Step: [200/285], Loss: 0.4103231728076935, Validation Acc:78.57142857142857, AUC:0.585411779232004\n",
      "Epoch: [7/10], Step: [100/285], Loss: 0.4164734184741974, Validation Acc:78.13664596273291, AUC:0.5874645017903445\n",
      "Epoch: [7/10], Step: [200/285], Loss: 0.5330530405044556, Validation Acc:79.56521739130434, AUC:0.5772471910112359\n",
      "Epoch: [8/10], Step: [100/285], Loss: 0.21922875940799713, Validation Acc:79.3167701863354, AUC:0.5911995308062724\n",
      "Epoch: [8/10], Step: [200/285], Loss: 0.31084001064300537, Validation Acc:79.62732919254658, AUC:0.574731448326954\n",
      "Epoch: [9/10], Step: [100/285], Loss: 0.3331621289253235, Validation Acc:79.25465838509317, AUC:0.5966323002839856\n",
      "Epoch: [9/10], Step: [200/285], Loss: 0.22866599261760712, Validation Acc:77.3913043478261, AUC:0.5884831460674158\n",
      "Epoch: [10/10], Step: [100/285], Loss: 0.4101548194885254, Validation Acc:77.7639751552795, AUC:0.5840844548709718\n",
      "Epoch: [10/10], Step: [200/285], Loss: 0.35175591707229614, Validation Acc:79.87577639751552, AUC:0.5948110877886159\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "LR = 0.002\n",
    "\n",
    "rnn_model = RNN(40, 1, len(vocabulary), 20)\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=LR)\n",
    "\n",
    "train(EPOCHS, rnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Play around with trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_sentence(sentence, model):\n",
    "    model.eval()\n",
    "    test_tensor = torch.LongTensor(sentences_to_padded_index_sequences(vocab_indices, [sentence]).astype(int))\n",
    "    score = model(Variable(test_tensor)).data.numpy()[0][0][0]\n",
    "    \n",
    "    return (\"positive\" if score > 0.5 else \"negative\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative', 0.15449949)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"her speech was great\", rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative', 0.28567505)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"His speech sucked\", rnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, \n",
    "                 vocab_size, embedding_dim, dropout=0.2):\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # TODO: LSTM with dropout, remember to set batch_firs to True\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self, bsz):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state values and C matrix for LSTM\n",
    "        :return (hidden, c)\n",
    "        \"\"\"\n",
    "        # TODO: initialize LSTM values\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward function of the network:\n",
    "        1. take the embedding vectors of each token index\n",
    "        2. pass embedding vectors to RNN/LSTM module\n",
    "        3. take last hidden state from RNN/LSTM module\n",
    "        4. pass last hidden state to linear layer to get output\n",
    "        :param x: LongTensor of shape (batch_size, pad_length)\n",
    "        :return a LongTensor of shape (batch_size, 1)\n",
    "        \"\"\"\n",
    "        x = self.emb(x)\n",
    "        # TODO: take last hidden state of RNN\n",
    "        \n",
    "        out = F.sigmoid(self.fc(last_hidden))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If everything is done correctly, you should be able to get about 85% accuracy and an AUC of about 0.75 after 10 epochs of training with the provided parameters with a LSTM. Note the significant improvement with a LSTM even without changing the parameters much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [100/285], Loss: 0.45670372247695923, Validation Acc:77.3913043478261, AUC:0.5\n",
      "Epoch: [1/10], Step: [200/285], Loss: 0.3691979646682739, Validation Acc:77.70186335403727, AUC:0.5107575009260402\n",
      "Epoch: [2/10], Step: [100/285], Loss: 0.44790759682655334, Validation Acc:79.5031055900621, AUC:0.6439375231510064\n",
      "Epoch: [2/10], Step: [200/285], Loss: 0.395826518535614, Validation Acc:80.55900621118012, AUC:0.6138103469564143\n",
      "Epoch: [3/10], Step: [100/285], Loss: 0.3412517309188843, Validation Acc:80.8695652173913, AUC:0.6576274848746758\n",
      "Epoch: [3/10], Step: [200/285], Loss: 0.46227243542671204, Validation Acc:82.04968944099379, AUC:0.6915051240893937\n",
      "Epoch: [4/10], Step: [100/285], Loss: 0.34477517008781433, Validation Acc:82.36024844720497, AUC:0.6400327200888999\n",
      "Epoch: [4/10], Step: [200/285], Loss: 0.3076227605342865, Validation Acc:82.29813664596273, AUC:0.6629676503272008\n",
      "Epoch: [5/10], Step: [100/285], Loss: 0.34102505445480347, Validation Acc:82.36024844720497, AUC:0.7119860476602049\n",
      "Epoch: [5/10], Step: [200/285], Loss: 0.30337467789649963, Validation Acc:82.6086956521739, AUC:0.6708081244598099\n",
      "Epoch: [6/10], Step: [100/285], Loss: 0.3613426387310028, Validation Acc:82.48447204968944, AUC:0.7020928509692554\n",
      "Epoch: [6/10], Step: [200/285], Loss: 0.22088058292865753, Validation Acc:83.2919254658385, AUC:0.7335627855290776\n",
      "Epoch: [7/10], Step: [100/285], Loss: 0.12783591449260712, Validation Acc:83.22981366459628, AUC:0.6981571798987529\n",
      "Epoch: [7/10], Step: [200/285], Loss: 0.36273688077926636, Validation Acc:83.72670807453416, AUC:0.7159525867391037\n",
      "Epoch: [8/10], Step: [100/285], Loss: 0.5338305830955505, Validation Acc:82.17391304347827, AUC:0.7282843560933449\n",
      "Epoch: [8/10], Step: [200/285], Loss: 0.09663775563240051, Validation Acc:83.41614906832298, AUC:0.6886652673169528\n",
      "Epoch: [9/10], Step: [100/285], Loss: 0.2486708164215088, Validation Acc:82.6086956521739, AUC:0.7009507346585999\n",
      "Epoch: [9/10], Step: [200/285], Loss: 0.1593797653913498, Validation Acc:82.54658385093168, AUC:0.7316644030127176\n",
      "Epoch: [10/10], Step: [100/285], Loss: 0.0789574682712555, Validation Acc:83.16770186335404, AUC:0.7454006667489814\n",
      "Epoch: [10/10], Step: [200/285], Loss: 0.3049306869506836, Validation Acc:83.22981366459628, AUC:0.7137146561303864\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "LR = 0.002\n",
    "\n",
    "lstm_model = LSTM(40, 1, len(vocabulary), 20)\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=LR)\n",
    "\n",
    "train(EPOCHS, lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Play around with trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('positive', 0.964622)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"I love this guy!\", lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('positive', 0.96462125)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"her speech was great\", lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative', 0.4483167)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence(\"His speech sucked\", lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Try at home:\n",
    "- Use the GloVe embedding as a pretrained embedding, and train it on our dataset (hint: nn.Embedding.weight). Remember to re-index the tokens!\n",
    "- Use the GloVe embedding, but keep the embedding fixed throughout training (hint: requires_grad=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
