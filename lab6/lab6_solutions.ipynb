{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (70000, 28, 28)\n",
      "ModuleList(\n",
      "  (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): ResidualBottleneck(\n",
      "    (conv1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (2): ResidualBottleneck(\n",
      "    (conv1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (4): ResidualBottleneck(\n",
      "    (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (5): ResidualBottleneck(\n",
      "    (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (6): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (7): ResidualBottleneck(\n",
      "    (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (8): ResidualBottleneck(\n",
      "    (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (9): Conv2d(128, 140, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (10): ResidualBottleneck(\n",
      "    (conv1): Conv2d(140, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(32, 140, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (11): Conv2d(140, 160, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (12): ResidualBottleneck(\n",
      "    (conv1): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (13): Conv2d(160, 200, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (14): ResidualBottleneck(\n",
      "    (conv1): Conv2d(200, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(64, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): LeakyReLU(0.01)\n",
      "  )\n",
      "  (15): Conv2d(200, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (16): Conv2d(256, 360, kernel_size=(2, 2), stride=(1, 1))\n",
      ")\n",
      "itr: 0\n",
      "itr: 100\n",
      "itr: 200\n",
      "itr: 300\n",
      "itr: 400\n",
      "itr: 500\n",
      "itr: 600\n",
      "itr: 700\n",
      "epoch: 0\n",
      "train loss:  5.0496832512562575\n",
      "val loss:  1.5736961795488743e+19\n",
      "val acc:  0.9784761904761905\n",
      "itr: 0\n",
      "itr: 100\n",
      "itr: 200\n",
      "itr: 300\n",
      "itr: 400\n",
      "itr: 500\n",
      "itr: 600\n",
      "itr: 700\n",
      "epoch: 1\n",
      "train loss:  1.9023341228175008\n",
      "val loss:  1.6885815588109156e+19\n",
      "val acc:  0.9833809523809524\n",
      "itr: 0\n",
      "itr: 100\n",
      "itr: 200\n",
      "itr: 300\n",
      "itr: 400\n",
      "itr: 500\n",
      "itr: 600\n",
      "itr: 700\n",
      "epoch: 2\n",
      "train loss:  1.3056685354390176\n",
      "val loss:  2.2045654744788107e+19\n",
      "val acc:  0.9862380952380952\n",
      "itr: 0\n",
      "itr: 100\n",
      "itr: 200\n",
      "itr: 300\n",
      "itr: 400\n",
      "itr: 500\n",
      "itr: 600\n",
      "itr: 700\n",
      "epoch: 3\n",
      "train loss:  0.9814475039835849\n",
      "val loss:  2.01496866493846e+19\n",
      "val acc:  0.9847142857142858\n",
      "itr: 0\n",
      "itr: 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9120f4815ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9120f4815ab0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, verbosity, val_freq)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtovar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;31m# Before the backward pass, use the optimizer object to zero all of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/python/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9120f4815ab0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0minput_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mxflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/python/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Lab4: Introduction to Convolutional Layers\n",
    "#\n",
    "# The goal of this lab is to understand mathematical motivations and thought processes behind a wide range of\n",
    "#  practical network augmentation approaches.\n",
    "#\n",
    "# For the specific task, we wanted to perform video classification. Unfortunately, video classification datasets are\n",
    "# very data and compute expensive, and so rather than downloading 100GB of youtube videos for lab we are going\n",
    "#  to simulate our own demo dataset.\n",
    "\n",
    "# The specific techiques we will cover today will be:\n",
    "# 1- Residual layers: https://arxiv.org/pdf/1512.03385.pdf\n",
    "#     1a- Residual Bottlenecking layers (same paper)\n",
    "# 2- Hidden Penalty layers (See Google's Inception or AlphaGo Zero)\n",
    "# 3- Adversarial Sampling (https://www.youtube.com/watch?v=CIfsB_EYsVI)\n",
    "# 4- (Optional) Recurrent networks with local connections and spatial parameter sharing https://arxiv.org/abs/1506.04214\n",
    "#\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# Import common dependencies\n",
    "import torch\n",
    "import pandas as pd  # noqa\n",
    "import numpy as np\n",
    "import matplotlib  # noqa\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime  # noqa\n",
    "import PIL  # noqa\n",
    "import glob  # noqa\n",
    "import pickle  # noqa\n",
    "from pathlib import Path  # noqa\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable  # noqa\n",
    "from scipy import misc  # noqa\n",
    "from torchvision.transforms import RandomRotation, RandomResizedCrop, ColorJitter, Compose\n",
    "\n",
    "# ## Dataset Selection\n",
    "#\n",
    "# ### First, read in the sample labels which we will treat as y classes, and split into trn and val\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def process_mnist():\n",
    "    import torchvision\n",
    "    data = torchvision.datasets.MNIST(root='.', download=True)\n",
    "    train_data = data.train_data.numpy()\n",
    "    train_labels = data.train_labels.numpy()\n",
    "\n",
    "    data_test = torchvision.datasets.MNIST(root='.', download=True, train=False)\n",
    "    test_data = data_test.test_data.numpy()\n",
    "    test_labels = data_test.test_labels.numpy()\n",
    "\n",
    "    data = np.concatenate([train_data, test_data], axis=0)\n",
    "    labels = np.concatenate([train_labels, test_labels], axis=0)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "data, labels = process_mnist()\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# Check the final shape of our in-use dataset\n",
    "print('data shape', data.shape)\n",
    "\n",
    "# Feature shapes\n",
    "num_rows, num_features = data.shape[0], data.shape[1]\n",
    "\n",
    "# Select Training rows\n",
    "np.random.seed(0)\n",
    "trn_rows = np.sort(np.random.choice(num_rows, size=int(num_rows * .7), replace=False))\n",
    "\n",
    "# Select Validation rows\n",
    "val_rows = np.setdiff1d(np.arange(num_rows), trn_rows)\n",
    "\n",
    "# Split dataset\n",
    "trn_data, val_data = data[trn_rows], data[val_rows]\n",
    "trn_Y, val_Y = labels[trn_rows], labels[val_rows]\n",
    "\n",
    "# already normalized when appropriate\n",
    "# Normalize training and validation based on training data\n",
    "data_max, data_min = trn_data.max(0), trn_data.min(0)\n",
    "data_diff = data_max - data_min + 1e-18\n",
    "\n",
    "\n",
    "def normalize_data(data, data_diff, data_min):\n",
    "    normalized = (data - np.expand_dims(data_min, 0)) / np.expand_dims(data_diff, 0)\n",
    "    return normalized\n",
    "\n",
    "\n",
    "trn_normalized = np.expand_dims(normalize_data(trn_data, data_diff, data_min), -1)\n",
    "val_normalized = np.expand_dims(normalize_data(val_data, data_diff, data_min), -1)\n",
    "trn_normalized = np.transpose(trn_normalized, [0, 3, 2, 1])\n",
    "val_normalized = np.transpose(val_normalized, [0, 3, 2, 1])\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "trn_normalized.max(), trn_normalized.min()\n",
    "\n",
    "\n",
    "# label_df = pd.read_csv('sample_labels.csv').iloc[:, :2]\n",
    "# label_df.index = label_df.iloc[:,0]\n",
    "# label_df = label_df.iloc[:,[1]]\n",
    "# label_df.columns = ['label']\n",
    "# num_rows = label_df.shape[0]\n",
    "# cutoff = .9\n",
    "# samples = np.random.rand(num_rows) < cutoff\n",
    "# trn, val = np.nonzero(samples)[0], np.nonzero(samples==0)[0]\n",
    "\n",
    "# ### Next, map labels to unique values, and drop all uncommon labels into a 'unknown' label\n",
    "\n",
    "#\n",
    "#\n",
    "# uni_lbls = label_df['label'].value_counts().sort_values(ascending=False)\n",
    "# lbls = uni_lbls[uni_lbls > 10]\n",
    "# lbl_keys = lbls.keys()\n",
    "# num_keys = len(lbl_keys)\n",
    "# lbl_idx = np.arange(num_keys)\n",
    "#\n",
    "# unk = 'unknown/uncommon'\n",
    "#\n",
    "# lbl_map = {key:idx for key, idx in zip(lbl_keys, lbl_idx)}\n",
    "# inv_lbl_map = {idx:key for key, idx in zip(lbl_keys, lbl_idx)}\n",
    "#\n",
    "# for lbl in label_df['label'].unique():\n",
    "#     if lbl not in lbl_map.keys():\n",
    "#         lbl_map[lbl] = num_keys\n",
    "# label_df['label_idx'] = label_df['label'].map(lbl_map)\n",
    "#\n",
    "#\n",
    "\n",
    "# ### Lets just visualize an image to see what we're looking at\n",
    "\n",
    "# ### Load in the corresponding images, or load in the pre processed numpy array that we use to store them.\n",
    "# ### Lets normalize them to [0,1]\n",
    "\n",
    "# my_file = Path(\"images.pickle\")\n",
    "# if not my_file.is_file():\n",
    "#     import skimage.measure\n",
    "#\n",
    "#     images = np.empty((num_rows, 64, 64))\n",
    "#     for idx,filename in enumerate(glob.glob('images/*')): #assuming gif\n",
    "#         im=misc.imread(filename)\n",
    "#         if im.shape[-1] < 5:\n",
    "#             im = im[:,:,0]\n",
    "#         im = skimage.measure.block_reduce(im, (16,16), np.max)\n",
    "#         images[idx,:,:] = im\n",
    "#\n",
    "#     images = np.reshape(images, [num_rows, 1, 64, 64])\n",
    "#     images = images - images.min()\n",
    "#     images = images/images.max()\n",
    "#     pickle.dump(images, open('images.pickle', 'wb'))\n",
    "# else:\n",
    "#     images = pickle.load(open('images.pickle','rb'))\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "plt.imshow(trn_normalized[0, 0, :, :])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "# Code to cleanly swap between Pytorch and Numpy.\n",
    "# Makes PyTorch much more user friendly, but not widely used.\n",
    "# Base code from Andy Gan (Github BarclayII) with some minor additions\n",
    "\n",
    "# Main adjustable flag. Enables or Disable GPU optimizations\n",
    "USE_CUDA = 1\n",
    "\n",
    "\n",
    "def cuda(obj):\n",
    "    if USE_CUDA:\n",
    "        if isinstance(obj, tuple):\n",
    "            return tuple(cuda(o) for o in obj)\n",
    "        elif isinstance(obj, list):\n",
    "            return list(cuda(o) for o in obj)\n",
    "        elif hasattr(obj, 'cuda'):\n",
    "            return obj.cuda()\n",
    "    return obj\n",
    "\n",
    "\n",
    "def tovar(*arrs, **kwargs):\n",
    "    tensors = [(torch.from_numpy(a) if isinstance(a, np.ndarray) else a) for a in arrs]\n",
    "    vars_ = [torch.autograd.Variable(t, **kwargs) for t in tensors]\n",
    "    if USE_CUDA:\n",
    "        vars_ = [v.cuda() for v in vars_]\n",
    "    return vars_[0] if len(vars_) == 1 else vars_\n",
    "\n",
    "\n",
    "def tonumpy(*vars_):\n",
    "    arrs = [(v.data.cpu().numpy() if isinstance(v, torch.autograd.Variable) else\n",
    "             v.cpu().numpy() if torch.is_tensor(v) else v) for v in vars_]\n",
    "    return arrs[0] if len(arrs) == 1 else arrs\n",
    "\n",
    "\n",
    "# ### Lets Build some fancy network architectures!\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, filters, kernel_size, relu=True):\n",
    "        nn.Module.__init__(self)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(in_channels=filters, out_channels=filters,\n",
    "                              kernel_size=kernel_size, stride=1, padding=padding)\n",
    "        if relu:\n",
    "            self.relu = nn.LeakyReLU()\n",
    "        else:\n",
    "            self.relu = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.conv(x)\n",
    "        if self.relu:\n",
    "            return self.relu(conv + x)\n",
    "        else:\n",
    "            return conv + x\n",
    "\n",
    "\n",
    "class ResidualBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels, kernel_size=3, relu=True):\n",
    "        nn.Module.__init__(self)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=hidden_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_channels, out_channels=hidden_channels,\n",
    "                               kernel_size=kernel_size, stride=1, padding=padding)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=hidden_channels, out_channels=out_channels,\n",
    "                               kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        if relu:\n",
    "            self.relu = nn.LeakyReLU()\n",
    "        else:\n",
    "            self.relu = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.conv1(x)\n",
    "        conv = self.relu(conv)\n",
    "        conv = self.conv2(conv)\n",
    "        conv = self.relu(conv)\n",
    "        conv = self.conv3(conv)\n",
    "        if self.relu:\n",
    "            return self.relu(conv + x)\n",
    "        else:\n",
    "            return conv + x\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# Build the network in pytorch\n",
    "\n",
    "def init_weights(module):\n",
    "    # Optional: Initialize weights using Xavier Initialization\n",
    "    for name, param in module.named_parameters():\n",
    "        if name.find('weight') != -1:\n",
    "            if len(param.size()) == 1:\n",
    "                init.uniform(param.data, 1)\n",
    "            else:\n",
    "                init.xavier_uniform(param.data)\n",
    "        elif name.find('bias') != -1:\n",
    "            init.constant(param.data, 0)\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    # Identity Module\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_layers, num_outputs, lr=1e-4):\n",
    "        # num_inputs is the number of input feature\n",
    "        # Hidden layers is a list of hidden layer sizes)\n",
    "        nn.Module.__init__(self)\n",
    "        self.output_layers = nn.ModuleList()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        prev_filters = 1\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        shape = input_shape\n",
    "        self.trn_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        if 1:\n",
    "            for idx, (filters, kernel_size, stride, padding) in enumerate(hidden_layers):\n",
    "                if (stride == 1) and (idx > 0) and (padding > 0):\n",
    "                    layer = ResidualBottleneck(\n",
    "                        in_channels=prev_filters, out_channels=prev_filters,\n",
    "                        hidden_channels=filters, kernel_size=kernel_size)\n",
    "                    self.hidden_layers.append(layer)\n",
    "                else:\n",
    "                    layer = nn.Conv2d(\n",
    "                        in_channels=prev_filters, out_channels=filters, kernel_size=kernel_size,\n",
    "                        stride=stride, padding=padding)\n",
    "                    self.hidden_layers.append(layer)\n",
    "                    prev_filters = filters\n",
    "                if idx == 0:\n",
    "                    self.first_layer = layer\n",
    "                shape = shape // stride\n",
    "                if padding == 0:\n",
    "                    shape = shape - 1\n",
    "                if (idx > 0) and (idx < len(hidden_layers) - 1) and (idx % 3) == 0:\n",
    "                    flat_size = prev_filters * shape * shape\n",
    "                    out_layer = nn.Linear(flat_size, num_outputs)\n",
    "                    self.output_layers.append(out_layer)\n",
    "            flat_size = prev_filters * shape * shape\n",
    "            out_layer = nn.Linear(flat_size, num_outputs)\n",
    "            self.output_layers.append(out_layer)\n",
    "        self.loss_fcn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.optimizer = torch.optim.RMSprop(self.parameters(), lr=lr, weight_decay=1e-8)\n",
    "        init_weights(self)\n",
    "        print(self.hidden_layers)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch_size = x.shape[0]\n",
    "        hidden_loss_idx = 0\n",
    "        x = tovar(x, requires_grad=True).float()\n",
    "        input_x = x\n",
    "        for idx, layer in enumerate(self.hidden_layers):\n",
    "            x = layer(x)\n",
    "            if (idx > 0) and (idx < len(hidden_layers) - 1) and (idx % 3) == 0:\n",
    "                xflat = x.view(batch_size, -1)\n",
    "                output = self.output_layers[hidden_loss_idx](xflat)\n",
    "                hidden_loss = self.loss_fcn(output, y) * tovar(np.array([1.5 ** hidden_loss_idx], dtype=np.float32))\n",
    "                if hidden_loss_idx == 0:\n",
    "                    loss = hidden_loss\n",
    "                else:\n",
    "                    loss += hidden_loss\n",
    "                hidden_loss_idx += 1\n",
    "        xflat = x.view(batch_size, -1)\n",
    "        output = self.output_layers[hidden_loss_idx](xflat)\n",
    "        hidden_loss = self.loss_fcn(output, y) * tovar(np.array([1.5 ** hidden_loss_idx], dtype=np.float32))\n",
    "        loss += hidden_loss\n",
    "        return output, loss, input_x\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def train(epochs=2, verbosity=0, val_freq=1):\n",
    "    num_epochs = epochs\n",
    "    bs = 64\n",
    "    rows_trn = len(trn_rows)\n",
    "    batches_per_epoch = rows_trn // bs\n",
    "    rows_val = len(val_rows)\n",
    "    batches_val = rows_val // bs\n",
    "    randomtransform = Compose([\n",
    "        RandomRotation(),\n",
    "        RandomResizedCros(),\n",
    "        ColorJitter(),\n",
    "    ])\n",
    "    for epoch in range(num_epochs):\n",
    "        # Optimize Model on mini batches\n",
    "        trn_loss = []\n",
    "        trn_acc = [0, 0]\n",
    "        order = np.arange(trn_normalized.shape[0])\n",
    "        np.random.shuffle(order)\n",
    "        for itr in range(batches_per_epoch):\n",
    "            rows = order[itr * bs:(itr + 1) * bs]\n",
    "            if itr + 1 == batches_per_epoch:\n",
    "                rows = order[itr * bs:]\n",
    "            samples = rows\n",
    "            x, y = trn_normalized[samples, :, :, :], trn_Y[samples]\n",
    "            x = randomtransform(x)\n",
    "            _, loss, input_x = model(x, tovar(y))\n",
    "\n",
    "            adv_grad = torch.autograd.grad(loss, input_x, grad_outputs=cuda(torch.ones(loss.size())),\n",
    "                                           create_graph=True, retain_graph=True, only_inputs=True)\n",
    "            adv = (adv_grad[0] > 0).type(torch.FloatTensor) * 1e-3 - \\\n",
    "                (adv_grad[0] < 0).type(torch.FloatTensor) * 1e-3\n",
    "            adv = tonumpy(adv.data)\n",
    "\n",
    "            x = x + adv\n",
    "\n",
    "            y_pred, loss, _ = model(x, tovar(y))\n",
    "\n",
    "            # Before the backward pass, use the optimizer object to zero all of the\n",
    "            # gradients for the variables it will update (which are the learnable weights of the model)\n",
    "            model.optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its parameters\n",
    "            model.optimizer.step()\n",
    "            trn_loss.append(tonumpy(loss.data[0]))\n",
    "            if itr % 100 == 0:\n",
    "                print('itr:', itr)\n",
    "        if epoch % val_freq == 0:\n",
    "            # Evaluate Performance on on validation set\n",
    "            # rows_val\n",
    "            y_pred_all = np.ones((0, 10))\n",
    "            val_loss_all = 0\n",
    "            for itr in range(batches_val):\n",
    "                rows = np.arange(itr * bs, (itr + 1) * bs)\n",
    "                if itr + 1 == batches_val:\n",
    "                    rows = np.arange(itr * bs, rows_val)\n",
    "                xval, yval = val_normalized[rows, :, :, :], val_Y[rows]\n",
    "                y_pred, loss, _ = model(xval, tovar(yval))\n",
    "                y_pred_all = np.concatenate((y_pred_all, (tonumpy(y_pred.data))), 0)\n",
    "                val_loss_all += loss.data[0]\n",
    "            y_pred_all = np.argmax(y_pred_all, 1)\n",
    "            acc = (y_pred_all == val_Y).mean()\n",
    "            trn_loss = np.mean(trn_loss)\n",
    "            model.trn_losses.append(trn_loss)\n",
    "            val_loss = tonumpy(val_loss_all)\n",
    "            print('epoch:', epoch)\n",
    "            print('train loss: ', trn_loss)\n",
    "            print('val loss: ', val_loss)\n",
    "            print('val acc: ', acc)\n",
    "            trn_loss = []\n",
    "            model.val_losses.append(val_loss)\n",
    "            model.val_acc.append(acc)\n",
    "\n",
    "\n",
    "def visualize(verbosity=0):\n",
    "    # Visualize performance of training and validation throughout training\n",
    "    print('Best Loss:', min(model.val_losses))\n",
    "    plt.close()\n",
    "    plt.plot(model.trn_losses, label='train loss')\n",
    "    plt.plot(model.val_losses, label='val loss')\n",
    "    plt.legend()\n",
    "    plt.title('losses')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.plot(model.val_acc, label='val accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('accuracy')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Now the code is done so lets test our model with different parameter settings!\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "num_epochs = 6\n",
    "verb = 0\n",
    "# As in model, hidden layers have order (filters, kernel_size, stride, padding, pool)\n",
    "# filters is the number of filters in the layer,\n",
    "# the layer has kernels of shape kernel_size x kernel_size,\n",
    "# stride is the stride length in each direction\n",
    "# padding is the padding width in each direction. consider (kernel_size -1)/2\n",
    "# pool is an indicator for pooling. 0 for convolution, 1 for pooling.\n",
    "\n",
    "# filters, kernel_size, stride\n",
    "hidden_layers = [\n",
    "    [32, 5, 1, 2],\n",
    "    [8, 3, 1, 1],\n",
    "    [8, 3, 1, 1],\n",
    "    [64, 5, 2, 2],\n",
    "    [16, 3, 1, 1],\n",
    "    [16, 3, 1, 1],\n",
    "    [128, 5, 2, 2],\n",
    "    [32, 3, 1, 1],\n",
    "    [32, 3, 1, 1],\n",
    "    [140, 2, 1, 0],\n",
    "    [32, 3, 1, 1],\n",
    "    [160, 2, 1, 0],\n",
    "    [64, 3, 1, 1],\n",
    "    [200, 2, 1, 0],\n",
    "    [64, 3, 1, 1],\n",
    "    [256, 2, 1, 0],\n",
    "    [360, 2, 1, 0],\n",
    "]\n",
    "\n",
    "\n",
    "model = cuda(Model(trn_normalized.shape[2], hidden_layers=hidden_layers, num_outputs=10))\n",
    "x = train(epochs=num_epochs, verbosity=verb)\n",
    "visualize()\n",
    "\n",
    "\n",
    "# ## Now lets visualize the types of features the early layers of the model has learned\n",
    "\n",
    "\n",
    "weights = tonumpy(model.first_layer.weight.data)\n",
    "\n",
    "\n",
    "# Code adapted from https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1\n",
    "def show_images(images, rows=1, titles=None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "\n",
    "    rows\n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None) or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['Image (%d)' % i for i in range(1, n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(rows, np.ceil(n_images / float(rows)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ## With a normal ML dataset we should see more reasonable learned features, I don't see\n",
    "# the model learning much with our tiny training efforts though.\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "show_images([weight[0] for weight in weights], rows=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
